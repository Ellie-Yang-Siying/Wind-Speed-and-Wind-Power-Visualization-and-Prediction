{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据集：**\n",
    "- Day 1-6: Train\n",
    "- Day 7-10: Validation\n",
    "- Day 11-13: Test\n",
    "\n",
    "**预测目标：**\n",
    "超短期预测（4h/15min）的风功率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 30, 40, 50])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集特征\n",
    "n_back = 400\n",
    "n_out = 16\n",
    "n_pre = n_out*15*2\n",
    "n_feature = 2\n",
    "\n",
    "train_day = 6\n",
    "validation_day = 4\n",
    "test_day = 3\n",
    "\n",
    "# 神经网络参数\n",
    "import numpy as np\n",
    "units = np.arange(20, 60, 10)\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "units"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 00:56:24.888193: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 00:56:25.555734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-12 00:56:25.555850: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-12 00:56:29.568887: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-12 00:56:29.569336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-12 00:56:29.569368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../wind_preprocessed.csv', header=0, index_col=0).query('day<14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       speed    power\n",
      "date                                 \n",
      "2015-10-01 00:00:00  0.39627  0.38065\n",
      "2015-10-01 00:00:30  0.39592  0.36943\n",
      "2015-10-01 00:01:00  0.39538  0.38529\n",
      "2015-10-01 00:01:30  0.39579  0.38892\n",
      "2015-10-01 00:02:00  0.39627  0.41220\n"
     ]
    }
   ],
   "source": [
    "data = dataset[['speed_moveavg', 'power_moveavg']].rename(columns={'power_moveavg':'power', 'speed_moveavg':'speed'})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = data.values\n",
    "values = values.astype('float32')\n",
    "\n",
    "def series_to_supervised(data, n_in, n_out, colname, dropnan=True):\n",
    "    n_vars = colname\n",
    "    # n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (j, i)) for j in n_vars]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out, 15*2):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('%s(t)' % (j)) for j in n_vars]\n",
    "        else:\n",
    "            names += [('%s(t+%d)' % (j, i)) for j in n_vars]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# 构建成监督学习问题\n",
    "reframed = series_to_supervised(values, n_back, n_pre, ['speed', 'power'])\n",
    "# 丢弃我们不想预测的列\n",
    "for i in range(0, n_pre, 15*2):\n",
    "    if i == 0:\n",
    "        colname = 'speed(t)'\n",
    "    else:\n",
    "        colname = f'speed(t+{i})'\n",
    "    reframed.drop(colname, axis=1, inplace=True)\n",
    "# print(reframed.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17280, 400, 2) (17280, 16)\n",
      "(11520, 400, 2) (11520, 16)\n",
      "(8640, 400, 2) (8640, 16)\n"
     ]
    }
   ],
   "source": [
    "# 分割为训练集和测试集\n",
    "values = reframed.values\n",
    "n_train = train_day*24*60*2\n",
    "n_validation = validation_day*24*60*2\n",
    "n_test = test_day*24*60*2\n",
    "train = values[:n_train, :]\n",
    "validation = values[n_train:n_train+n_validation, :]\n",
    "test = values[-n_test:, :]\n",
    "# 分为输入输出\n",
    "n_obs = n_back * n_feature\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_out:]\n",
    "validation_X, validation_y = validation[:, :n_obs], validation[:, -n_out:]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_out:]\n",
    "# 重塑成3D格式 [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_back, n_feature))\n",
    "validation_X = validation_X.reshape((validation_X.shape[0], n_back, n_feature))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_back, n_feature))\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(validation_X.shape, validation_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start Unit 20---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 00:57:05.528463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-12 00:57:05.528590: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-12 00:57:05.528649: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-VC833VJB): /proc/driver/nvidia/version does not exist\n",
      "2023-01-12 00:57:05.529347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-12 00:57:07.780319: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 55296000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "540/540 [==============================] - 344s 620ms/step - loss: 0.0316 - val_loss: 0.0430\n",
      "Epoch 2/50\n",
      "540/540 [==============================] - 334s 618ms/step - loss: 0.0336 - val_loss: 0.0291\n",
      "Epoch 3/50\n",
      "540/540 [==============================] - 364s 674ms/step - loss: 0.0308 - val_loss: 0.0292\n",
      "Epoch 4/50\n",
      "540/540 [==============================] - 363s 672ms/step - loss: 0.0291 - val_loss: 0.0255\n",
      "Epoch 5/50\n",
      "540/540 [==============================] - 363s 673ms/step - loss: 0.0276 - val_loss: 0.0234\n",
      "Epoch 6/50\n",
      "540/540 [==============================] - 363s 673ms/step - loss: 0.0266 - val_loss: 0.0218\n",
      "Epoch 7/50\n",
      "540/540 [==============================] - 362s 670ms/step - loss: 0.0262 - val_loss: 0.0210\n",
      "Epoch 8/50\n",
      "540/540 [==============================] - 362s 670ms/step - loss: 0.0257 - val_loss: 0.0204\n",
      "Epoch 9/50\n",
      "540/540 [==============================] - 377s 698ms/step - loss: 0.0253 - val_loss: 0.0196\n",
      "Epoch 10/50\n",
      "540/540 [==============================] - 373s 691ms/step - loss: 0.0250 - val_loss: 0.0190\n",
      "Epoch 11/50\n",
      "540/540 [==============================] - 391s 724ms/step - loss: 0.0247 - val_loss: 0.0183\n",
      "Epoch 12/50\n",
      "540/540 [==============================] - 347s 643ms/step - loss: 0.0245 - val_loss: 0.0177\n",
      "Epoch 13/50\n",
      "540/540 [==============================] - 356s 659ms/step - loss: 0.0243 - val_loss: 0.0175\n",
      "Epoch 14/50\n",
      "540/540 [==============================] - 359s 665ms/step - loss: 0.0241 - val_loss: 0.0173\n",
      "Epoch 15/50\n",
      "540/540 [==============================] - 357s 662ms/step - loss: 0.0240 - val_loss: 0.0168\n",
      "Epoch 16/50\n",
      "540/540 [==============================] - 354s 657ms/step - loss: 0.0238 - val_loss: 0.0162\n",
      "Epoch 17/50\n",
      "540/540 [==============================] - 348s 645ms/step - loss: 0.0236 - val_loss: 0.0160\n",
      "Epoch 18/50\n",
      "540/540 [==============================] - 346s 640ms/step - loss: 0.0235 - val_loss: 0.0156\n",
      "Epoch 19/50\n",
      "540/540 [==============================] - 425s 788ms/step - loss: 0.0233 - val_loss: 0.0152\n",
      "Epoch 20/50\n",
      "540/540 [==============================] - 356s 660ms/step - loss: 0.0232 - val_loss: 0.0150\n",
      "Epoch 21/50\n",
      "540/540 [==============================] - 337s 624ms/step - loss: 0.0231 - val_loss: 0.0149\n",
      "Epoch 22/50\n",
      "540/540 [==============================] - 335s 621ms/step - loss: 0.0231 - val_loss: 0.0145\n",
      "Epoch 23/50\n",
      "540/540 [==============================] - 335s 620ms/step - loss: 0.0229 - val_loss: 0.0144\n",
      "Epoch 24/50\n",
      "540/540 [==============================] - 341s 633ms/step - loss: 0.0228 - val_loss: 0.0141\n",
      "Epoch 25/50\n",
      "540/540 [==============================] - 345s 640ms/step - loss: 0.0226 - val_loss: 0.0139\n",
      "Epoch 26/50\n",
      "540/540 [==============================] - 345s 639ms/step - loss: 0.0225 - val_loss: 0.0136\n",
      "Epoch 27/50\n",
      "540/540 [==============================] - 345s 639ms/step - loss: 0.0223 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "540/540 [==============================] - 350s 649ms/step - loss: 0.0222 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "540/540 [==============================] - 356s 660ms/step - loss: 0.0221 - val_loss: 0.0131\n",
      "Epoch 30/50\n",
      "540/540 [==============================] - 366s 677ms/step - loss: 0.0219 - val_loss: 0.0130\n",
      "Epoch 31/50\n",
      "540/540 [==============================] - 355s 658ms/step - loss: 0.0218 - val_loss: 0.0130\n",
      "Epoch 32/50\n",
      "540/540 [==============================] - 382s 708ms/step - loss: 0.0217 - val_loss: 0.0130\n",
      "Epoch 33/50\n",
      "540/540 [==============================] - 354s 656ms/step - loss: 0.0217 - val_loss: 0.0129\n",
      "Epoch 34/50\n",
      "540/540 [==============================] - 385s 713ms/step - loss: 0.0216 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "540/540 [==============================] - 424s 785ms/step - loss: 0.0215 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "540/540 [==============================] - 361s 668ms/step - loss: 0.0215 - val_loss: 0.0128\n",
      "Epoch 37/50\n",
      "540/540 [==============================] - 364s 674ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 38/50\n",
      "540/540 [==============================] - 364s 675ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 39/50\n",
      "540/540 [==============================] - 388s 719ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 40/50\n",
      "540/540 [==============================] - 376s 696ms/step - loss: 0.0213 - val_loss: 0.0128\n",
      "Epoch 41/50\n",
      "540/540 [==============================] - 365s 677ms/step - loss: 0.0213 - val_loss: 0.0127\n",
      "Epoch 42/50\n",
      "540/540 [==============================] - 369s 683ms/step - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 43/50\n",
      "540/540 [==============================] - 359s 666ms/step - loss: 0.0212 - val_loss: 0.0127\n",
      "Epoch 44/50\n",
      "540/540 [==============================] - 357s 661ms/step - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 45/50\n",
      "540/540 [==============================] - 361s 668ms/step - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "540/540 [==============================] - 368s 681ms/step - loss: 0.0211 - val_loss: 0.0127\n",
      "Epoch 47/50\n",
      "540/540 [==============================] - 367s 680ms/step - loss: 0.0210 - val_loss: 0.0127\n",
      "Epoch 48/50\n",
      "540/540 [==============================] - 368s 681ms/step - loss: 0.0210 - val_loss: 0.0126\n",
      "Epoch 49/50\n",
      "540/540 [==============================] - 394s 730ms/step - loss: 0.0210 - val_loss: 0.0126\n",
      "Epoch 50/50\n",
      "540/540 [==============================] - 371s 688ms/step - loss: 0.0209 - val_loss: 0.0126\n",
      "---Finish Unit 20---\n",
      "---Start Unit 30---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-12 05:59:23.984541: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 55296000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "540/540 [==============================] - 407s 741ms/step - loss: 0.0285 - val_loss: 0.0422\n",
      "Epoch 2/50\n",
      "540/540 [==============================] - 447s 828ms/step - loss: 0.0341 - val_loss: 0.0316\n",
      "Epoch 3/50\n",
      "540/540 [==============================] - 391s 725ms/step - loss: 0.0312 - val_loss: 0.0277\n",
      "Epoch 4/50\n",
      "540/540 [==============================] - 451s 836ms/step - loss: 0.0290 - val_loss: 0.0248\n",
      "Epoch 5/50\n",
      "540/540 [==============================] - 407s 754ms/step - loss: 0.0278 - val_loss: 0.0233\n",
      "Epoch 6/50\n",
      "540/540 [==============================] - 448s 829ms/step - loss: 0.0269 - val_loss: 0.0216\n",
      "Epoch 7/50\n",
      "540/540 [==============================] - 402s 744ms/step - loss: 0.0262 - val_loss: 0.0204\n",
      "Epoch 8/50\n",
      "540/540 [==============================] - 477s 884ms/step - loss: 0.0256 - val_loss: 0.0194\n",
      "Epoch 9/50\n",
      "540/540 [==============================] - 401s 743ms/step - loss: 0.0253 - val_loss: 0.0185\n",
      "Epoch 10/50\n",
      "540/540 [==============================] - 396s 733ms/step - loss: 0.0249 - val_loss: 0.0175\n",
      "Epoch 11/50\n",
      "540/540 [==============================] - 455s 843ms/step - loss: 0.0245 - val_loss: 0.0169\n",
      "Epoch 12/50\n",
      "540/540 [==============================] - 460s 852ms/step - loss: 0.0242 - val_loss: 0.0166\n",
      "Epoch 13/50\n",
      "540/540 [==============================] - 456s 846ms/step - loss: 0.0240 - val_loss: 0.0158\n",
      "Epoch 14/50\n",
      "540/540 [==============================] - 406s 752ms/step - loss: 0.0237 - val_loss: 0.0152\n",
      "Epoch 15/50\n",
      "540/540 [==============================] - 413s 766ms/step - loss: 0.0235 - val_loss: 0.0154\n",
      "Epoch 16/50\n",
      "540/540 [==============================] - 477s 884ms/step - loss: 0.0233 - val_loss: 0.0153\n",
      "Epoch 17/50\n",
      "540/540 [==============================] - 409s 757ms/step - loss: 0.0232 - val_loss: 0.0150\n",
      "Epoch 18/50\n",
      "540/540 [==============================] - 462s 856ms/step - loss: 0.0230 - val_loss: 0.0144\n",
      "Epoch 19/50\n",
      "540/540 [==============================] - 411s 761ms/step - loss: 0.0227 - val_loss: 0.0140\n",
      "Epoch 20/50\n",
      "540/540 [==============================] - 469s 869ms/step - loss: 0.0226 - val_loss: 0.0142\n",
      "Epoch 21/50\n",
      "540/540 [==============================] - 408s 756ms/step - loss: 0.0225 - val_loss: 0.0141\n",
      "Epoch 22/50\n",
      "540/540 [==============================] - 401s 742ms/step - loss: 0.0223 - val_loss: 0.0138\n",
      "Epoch 23/50\n",
      "540/540 [==============================] - 456s 844ms/step - loss: 0.0222 - val_loss: 0.0138\n",
      "Epoch 24/50\n",
      "540/540 [==============================] - 423s 784ms/step - loss: 0.0221 - val_loss: 0.0136\n",
      "Epoch 25/50\n",
      "540/540 [==============================] - 416s 770ms/step - loss: 0.0220 - val_loss: 0.0135\n",
      "Epoch 26/50\n",
      "540/540 [==============================] - 403s 747ms/step - loss: 0.0220 - val_loss: 0.0134\n",
      "Epoch 27/50\n",
      "540/540 [==============================] - 457s 846ms/step - loss: 0.0219 - val_loss: 0.0134\n",
      "Epoch 28/50\n",
      "540/540 [==============================] - 408s 757ms/step - loss: 0.0218 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "540/540 [==============================] - 461s 855ms/step - loss: 0.0217 - val_loss: 0.0132\n",
      "Epoch 30/50\n",
      "540/540 [==============================] - 464s 860ms/step - loss: 0.0217 - val_loss: 0.0131\n",
      "Epoch 31/50\n",
      "540/540 [==============================] - 460s 852ms/step - loss: 0.0217 - val_loss: 0.0131\n",
      "Epoch 32/50\n",
      "540/540 [==============================] - 428s 793ms/step - loss: 0.0216 - val_loss: 0.0131\n",
      "Epoch 33/50\n",
      "540/540 [==============================] - 479s 887ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 34/50\n",
      "540/540 [==============================] - 456s 845ms/step - loss: 0.0215 - val_loss: 0.0129\n",
      "Epoch 35/50\n",
      "540/540 [==============================] - 412s 763ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 36/50\n",
      "540/540 [==============================] - 425s 787ms/step - loss: 0.0214 - val_loss: 0.0128\n",
      "Epoch 37/50\n",
      "241/540 [============>.................] - ETA: 3:36 - loss: 0.0164"
     ]
    }
   ],
   "source": [
    "def train(u):\n",
    "    print(f'---Start Unit {u}---')\n",
    "    # 设计网络\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(u, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(n_out))\n",
    "\n",
    "    # 拟合神经网络模型\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size, validation_data=(validation_X, validation_y), verbose=1, shuffle=False)\n",
    "    \n",
    "    # 保存模型及训练历史\n",
    "    model.save_weights(f'{u}.h5')\n",
    "    with open(f'lstm_unit{u}_hist.pickle', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "    \n",
    "    # 画图\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(history.history['loss'], label='train')\n",
    "    ax.plot(history.history['val_loss'], label='test')\n",
    "    plt.title(f'units_{u}')\n",
    "    plt.savefig(f'units_{u}.png')\n",
    "\n",
    "    print(f'---Finish Unit {u}---')\n",
    "\n",
    "for u in units:\n",
    "    train(u)\n",
    "# from multiprocessing.pool import ThreadPool\n",
    "# pool = ThreadPool(len(units))  # 创建一个线程池\n",
    "# pool.map(train, units)  # 往线程池中填线程\n",
    "# pool.close()  # 关闭线程池，不再接受线程\n",
    "# pool.join()  # 等待线程池中线程全部执行完"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5770e3b25a98de75bce43f2f8d39d9898bdd15f26b6dfc4856e2120567bac70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
